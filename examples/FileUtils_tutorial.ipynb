{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# FileUtils Tutorial\n",
       "\n",
       "This notebook demonstrates how to use FileUtils for data management in Python data science projects. We'll cover:\n",
       "1. Installation and Setup\n",
       "2. Basic File Operations\n",
       "3. Working with Different File Formats\n",
       "4. Azure Storage Integration\n",
       "5. Advanced Features\n",
       "\n",
       "## 1. Installation and Setup\n",
       "\n",
       "First, let's install FileUtils and set up our environment:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Install FileUtils with all features\n",
       "!pip install FileUtils[azure,parquet,excel]"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Import required packages\n",
       "import pandas as pd\n",
       "import numpy as np\n",
       "from pathlib import Path\n",
       "from FileUtils import FileUtils, OutputFileType\n",
       "\n",
       "# Initialize FileUtils\n",
       "file_utils = FileUtils()\n",
       "\n",
       "# Create some sample data\n",
       "np.random.seed(42)\n",
       "df = pd.DataFrame({\n",
       "    'date': pd.date_range('2024-01-01', periods=10),\n",
       "    'value': np.random.randn(10),\n",
       "    'category': np.random.choice(['A', 'B', 'C'], 10)\n",
       "})"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 2. Basic File Operations\n",
       "\n",
       "Let's start with basic file operations using different formats:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Save as CSV\n",
       "csv_files, _ = file_utils.save_data_to_disk(\n",
       "    data=df,\n",
       "    output_filetype=OutputFileType.CSV,\n",
       "    output_type=\"processed\",\n",
       "    file_name=\"sample_data\"\n",
       ")\n",
       "\n",
       "# Load CSV and verify\n",
       "loaded_csv = file_utils.load_single_file(\n",
       "    list(csv_files.values())[0],\n",
       "    input_type=\"processed\"\n",
       ")\n",
       "print(\"Loaded CSV data:\")\n",
       "print(loaded_csv.head())"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Working with Multiple DataFrames\n",
       "\n",
       "FileUtils can handle multiple DataFrames in a single file:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Create multiple DataFrames\n",
       "df_dict = {\n",
       "    'original': df,\n",
       "    'filtered': df[df['value'] > 0],\n",
       "    'summary': df.groupby('category')['value'].agg(['mean', 'count']).reset_index()\n",
       "}\n",
       "\n",
       "# Save to Excel with multiple sheets\n",
       "excel_files, _ = file_utils.save_data_to_disk(\n",
       "    data=df_dict,\n",
       "    output_filetype=OutputFileType.XLSX,\n",
       "    output_type=\"processed\",\n",
       "    file_name=\"multi_sheet_data\"\n",
       ")\n",
       "\n",
       "# Load all sheets\n",
       "loaded_sheets = file_utils.load_excel_sheets(\n",
       "    list(excel_files.values())[0],\n",
       "    input_type=\"processed\"\n",
       ")\n",
       "\n",
       "print(\"\\nLoaded Excel sheets:\")\n",
       "for sheet_name, sheet_df in loaded_sheets.items():\n",
       "    print(f\"\\n{sheet_name}:\")\n",
       "    print(sheet_df.head())"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 3. Working with Different File Formats\n",
       "\n",
       "FileUtils supports various file formats including CSV, Excel, Parquet, JSON, and YAML:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Save data in different formats\n",
       "formats = {\n",
       "    OutputFileType.CSV: \"csv_data\",\n",
       "    OutputFileType.XLSX: \"excel_data\",\n",
       "    OutputFileType.PARQUET: \"parquet_data\"\n",
       "}\n",
       "\n",
       "for format_type, filename in formats.items():\n",
       "    saved_files, _ = file_utils.save_data_to_disk(\n",
       "        data=df,\n",
       "        output_filetype=format_type,\n",
       "        output_type=\"processed\",\n",
       "        file_name=filename\n",
       "    )\n",
       "    print(f\"Saved {format_type.value} file: {list(saved_files.values())[0]}\")\n",
       "    \n",
       "    # Load and verify\n",
       "    loaded_df = file_utils.load_single_file(\n",
       "        list(saved_files.values())[0],\n",
       "        input_type=\"processed\"\n",
       "    )\n",
       "    print(f\"Successfully loaded {format_type.value} data with shape {loaded_df.shape}\\n\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 4. Azure Storage Integration\n",
       "\n",
       "To use Azure Storage, make sure you have set up your credentials in a .env file first. Let's verify the setup:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "from FileUtils.azure_setup import AzureSetupUtils\n",
       "\n",
       "# Validate Azure setup\n",
       "try:\n",
       "    is_valid = AzureSetupUtils.validate_azure_setup()\n",
       "    if is_valid:\n",
       "        print(\"Azure setup is valid\")\n",
       "        \n",
       "        # Initialize Azure-enabled FileUtils\n",
       "        azure_utils = FileUtils.create_azure_utils()\n",
       "        \n",
       "        # Save to Azure\n",
       "        saved_files, _ = azure_utils.save_data_to_disk(\n",
       "            data=df,\n",
       "            output_filetype=\"csv\",\n",
       "            output_type=\"processed\",\n",
       "            file_name=\"azure_data\"\n",
       "        )\n",
       "        print(f\"\\nSaved to Azure: {saved_files}\")\n",
       "        \n",
       "        # Load from Azure\n",
       "        azure_path = list(saved_files.values())[0]\n",
       "        loaded_df = azure_utils.load_single_file(azure_path)\n",
       "        print(\"\\nLoaded from Azure:\")\n",
       "        print(loaded_df.head())\n",
       "    else:\n",
       "        print(\"Azure setup is not valid - skipping Azure examples\")\n",
       "except Exception as e:\n",
       "    print(f\"Azure setup not configured: {e}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 5. Advanced Features\n",
       "\n",
       "Let's explore some advanced features of FileUtils:"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 5.1 Custom Configuration"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "import yaml\n",
       "\n",
       "# Create custom config\n",
       "config = {\n",
       "    'csv_delimiter': '|',\n",
       "    'encoding': 'utf-8',\n",
       "    'include_timestamp': True,\n",
       "    'logging_level': 'DEBUG',\n",
       "    'directory_structure': {\n",
       "        'data': ['raw', 'interim', 'processed', 'external'],\n",
       "        'reports': ['figures', 'tables']\n",
       "    }\n",
       "}\n",
       "\n",
       "config_path = Path('custom_config.yaml')\n",
       "with open(config_path, 'w') as f:\n",
       "    yaml.dump(config, f)\n",
       "\n",
       "# Initialize with custom config\n",
       "custom_utils = FileUtils(config_file=config_path)\n",
       "\n",
       "# Test custom delimiter\n",
       "saved_files, _ = custom_utils.save_data_to_disk(\n",
       "    data=df,\n",
       "    output_filetype=OutputFileType.CSV,\n",
       "    output_type=\"processed\",\n",
       "    file_name=\"custom_delim_data\"\n",
       ")\n",
       "\n",
       "# View the file contents\n",
       "with open(list(saved_files.values())[0], 'r') as f:\n",
       "    print(\"CSV with custom delimiter:\")\n",
       "    print(f.readline().strip())  # Print header row"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 5.2 Error Handling"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Try to load non-existent file\n",
       "try:\n",
       "    file_utils.load_single_file(\"nonexistent.csv\")\n",
       "except FileNotFoundError as e:\n",
       "    print(f\"Expected error: {e}\")\n",
       "\n",
       "# Try invalid file type\n",
       "try:\n",
       "    file_utils.save_data_to_disk(\n",
       "        data=df,\n",
       "        output_filetype=\"invalid\"\n",
       "    )\n",
       "except ValueError as e:\n",
       "    print(f\"Expected error: {e}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Cleanup\n",
       "\n",
       "Clean up temporary files created during this tutorial:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Remove custom config file\n",
       "if config_path.exists():\n",
       "    config_path.unlink()\n",
       "print(\"Cleanup completed\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Next Steps\n",
       "\n",
       "You've now seen the main features of FileUtils. Here are some suggestions for further exploration:\n",
       "\n",
       "1. Customize the directory structure for your project\n",
       "2. Experiment with different file formats and options\n",
       "3. Set up Azure Storage for cloud integration\n",
       "4. Create your own configuration file\n",
       "5. Explore the logging capabilities\n",
       "\n",
       "For more information, check the documentation or create an issue on GitHub if you have questions."
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }