"""Example: Excel to CSV Conversion with Workbook Structure

This script demonstrates the new Excel to CSV conversion functionality that
maintains workbook structure in a JSON file. This is particularly useful for
data pipelines that need to convert Excel workbooks to CSV format while
preserving metadata about the original workbook structure.

Features demonstrated:
- Convert Excel workbook with multiple sheets to individual CSV files
- Create structure JSON with sheet metadata and relationships
- Handle different Excel file configurations
- Load and inspect the converted data
"""

import sys
from pathlib import Path
import pandas as pd
import json

# Add project src directory to path (for local development)
project_root = Path(__file__).resolve().parent.parent
src_path = str(project_root / "src")
if src_path not in sys.path:
    sys.path.insert(0, src_path)  # Insert at beginning to prioritize

from FileUtils import FileUtils, OutputFileType


def create_sample_excel_workbook():
    """Create a sample Excel workbook with multiple sheets for demonstration."""
    print("=== Creating Sample Excel Workbook ===\n")
    
    file_utils = FileUtils()
    
    # Create sample data for different sheets
    # Sheet 1: Employee data
    employees_df = pd.DataFrame({
        'employee_id': [1, 2, 3, 4, 5],
        'name': ['Alice Johnson', 'Bob Smith', 'Charlie Brown', 'Diana Prince', 'Eve Wilson'],
        'department': ['Engineering', 'Marketing', 'Engineering', 'HR', 'Finance'],
        'salary': [75000, 65000, 80000, 60000, 70000],
        'hire_date': pd.date_range('2020-01-01', periods=5, freq='M')
    })
    
    # Sheet 2: Department summary
    departments_df = pd.DataFrame({
        'department': ['Engineering', 'Marketing', 'HR', 'Finance'],
        'head_count': [2, 1, 1, 1],
        'avg_salary': [77500, 65000, 60000, 70000],
        'budget': [200000, 100000, 80000, 120000]
    })
    
    # Sheet 3: Project assignments
    projects_df = pd.DataFrame({
        'project_id': ['P001', 'P002', 'P003'],
        'project_name': ['Website Redesign', 'Mobile App', 'Data Migration'],
        'lead_employee_id': [1, 2, 3],
        'status': ['In Progress', 'Planning', 'Completed'],
        'start_date': pd.date_range('2024-01-01', periods=3, freq='M')
    })
    
    # Combine all sheets
    workbook_data = {
        'Employees': employees_df,
        'Departments': departments_df,
        'Projects': projects_df
    }
    
    # Save as Excel workbook
    saved_files, metadata = file_utils.save_data_to_storage(
        data=workbook_data,
        output_filetype=OutputFileType.XLSX,
        output_type="raw",
        file_name="sample_workbook"
    )
    
    excel_file_path = list(saved_files.values())[0]
    print(f"‚úì Created sample Excel workbook: {excel_file_path}")
    print(f"  - Sheets: {list(workbook_data.keys())}")
    print(f"  - Total records: {sum(len(df) for df in workbook_data.values())}")
    
    return excel_file_path


def demonstrate_excel_to_csv_conversion():
    """Demonstrate Excel to CSV conversion with structure preservation."""
    print("\n=== Excel to CSV Conversion Demo ===\n")
    
    file_utils = FileUtils()
    
    # First, create a sample Excel workbook
    excel_file_path = create_sample_excel_workbook()
    
    # Convert Excel to CSV with structure preservation
    print("Converting Excel workbook to CSV files...")
    csv_files, structure_file = file_utils.convert_excel_to_csv_with_structure(
        excel_file_path=excel_file_path,
        input_type="raw",
        output_type="processed",
        file_name="converted_workbook",
        preserve_structure=True
    )
    
    print(f"\n‚úì Conversion completed!")
    print(f"  - CSV files created: {len(csv_files)}")
    print(f"  - Structure file: {structure_file}")
    
    # Display results
    print(f"\nüìÅ Generated Files:")
    for sheet_name, csv_path in csv_files.items():
        print(f"  - {sheet_name}: {csv_path}")
    print(f"  - Structure: {structure_file}")
    
    return csv_files, structure_file, excel_file_path


def inspect_structure_file(structure_file_path):
    """Inspect and display the structure JSON file contents."""
    print(f"\n=== Structure File Analysis ===")
    print(f"File: {structure_file_path}\n")
    
    # Load and display structure information
    with open(structure_file_path, 'r') as f:
        structure_data = json.load(f)
    
    # Workbook info
    workbook_info = structure_data['workbook_info']
    print(f"üìä Workbook Information:")
    print(f"  - Source file: {workbook_info['source_file']}")
    print(f"  - Conversion time: {workbook_info['conversion_timestamp']}")
    print(f"  - Total sheets: {workbook_info['total_sheets']}")
    print(f"  - Sheet names: {workbook_info['sheet_names']}")
    
    # Sheet details
    print(f"\nüìã Sheet Details:")
    for sheet_name, sheet_info in structure_data['sheets'].items():
        print(f"\n  {sheet_name}:")
        print(f"    - CSV file: {sheet_info['csv_filename']}")
        print(f"    - Dimensions: {sheet_info['dimensions']['rows']} rows √ó {sheet_info['dimensions']['columns']} columns")
        print(f"    - Columns: {sheet_info['columns']['names']}")
        print(f"    - Data types: {sheet_info['columns']['dtypes']}")
        print(f"    - Memory usage: {sheet_info['data_info']['memory_usage']:,} bytes")
        print(f"    - Null values: {sum(sheet_info['data_info']['null_counts'].values())} total")


def demonstrate_csv_loading(csv_files):
    """Demonstrate loading the converted CSV files."""
    print(f"\n=== Loading Converted CSV Files ===")
    
    file_utils = FileUtils()
    
    for sheet_name, csv_path in csv_files.items():
        print(f"\nüìÑ Loading {sheet_name}:")
        
        # Load the CSV file
        df = file_utils.load_single_file(
            Path(csv_path).name,  # Just the filename
            input_type="processed"
        )
        
        print(f"  - Shape: {df.shape}")
        print(f"  - Columns: {list(df.columns)}")
        print(f"  - First few rows:")
        print(df.head(2).to_string(index=False))
        print("  " + "-" * 50)


def demonstrate_advanced_features():
    """Demonstrate advanced features of the conversion."""
    print(f"\n=== Advanced Features Demo ===")
    
    file_utils = FileUtils()
    
    # Create another sample workbook with different characteristics
    print("Creating workbook with special characteristics...")
    
    # Sheet with missing values and different data types
    special_df = pd.DataFrame({
        'id': [1, 2, 3, 4],
        'name': ['Item A', 'Item B', None, 'Item D'],
        'price': [10.50, None, 25.00, 15.75],
        'category': ['A', 'B', 'A', 'C'],
        'active': [True, False, True, True]
    })
    
    # Sheet with datetime and complex data
    datetime_df = pd.DataFrame({
        'event_id': [1, 2, 3],
        'event_name': ['Meeting', 'Conference', 'Workshop'],
        'start_time': pd.date_range('2024-01-01', periods=3, freq='D'),
        'duration_hours': [1.5, 8.0, 4.0],
        'attendees': [[10, 20, 30], [50, 60, 70], [15, 25, 35]]  # List data
    })
    
    advanced_workbook = {
        'Special_Data': special_df,
        'Events': datetime_df
    }
    
    # Save advanced workbook
    saved_files, _ = file_utils.save_data_to_storage(
        data=advanced_workbook,
        output_filetype=OutputFileType.XLSX,
        output_type="raw",
        file_name="advanced_workbook"
    )
    
    excel_file_path = list(saved_files.values())[0]
    
    # Convert with custom options
    print("Converting with custom CSV options...")
    csv_files, structure_file = file_utils.convert_excel_to_csv_with_structure(
        excel_file_path=excel_file_path,
        input_type="raw",
        output_type="processed",
        file_name="advanced_converted",
        preserve_structure=True,
        encoding="utf-8",
        sep=","  # Custom delimiter
    )
    
    print(f"‚úì Advanced conversion completed!")
    print(f"  - Files: {list(csv_files.keys())}")
    
    # Show how the structure file handles special data
    print(f"\nüîç Special Data Handling:")
    with open(structure_file, 'r') as f:
        structure_data = json.load(f)
    
    special_sheet = structure_data['sheets']['Special_Data']
    print(f"  - Null handling: {special_sheet['data_info']['null_counts']}")
    print(f"  - Data types preserved: {special_sheet['columns']['dtypes']}")


def demonstrate_workflow_integration(excel_file_path):
    """Demonstrate how this fits into a typical data workflow."""
    print(f"\n=== Workflow Integration Example ===")
    
    file_utils = FileUtils()
    
    # Simulate a typical data pipeline
    print("üîÑ Simulating data pipeline workflow...")
    
    # Step 1: Convert Excel to CSV
    print("1. Converting Excel workbook to CSV format...")
    csv_files, structure_file = file_utils.convert_excel_to_csv_with_structure(
        excel_file_path,  # Use the actual file path from earlier
        input_type="raw",
        output_type="processed",
        file_name="pipeline_data"
    )
    
    # Step 2: Load and process data
    print("2. Loading and processing converted data...")
    employees_df = file_utils.load_single_file(
        Path(csv_files['Employees']).name,
        input_type="processed"
    )
    
    # Step 3: Perform analysis
    print("3. Performing analysis...")
    dept_summary = employees_df.groupby('department').agg({
        'salary': ['mean', 'count'],
        'employee_id': 'count'
    }).round(2)
    
    print("   Department Summary:")
    print(dept_summary.to_string())
    
    # Step 4: Save results
    print("4. Saving analysis results...")
    file_utils.save_data_to_storage(
        data=dept_summary,
        output_filetype=OutputFileType.CSV,
        output_type="processed",
        file_name="department_analysis"
    )
    
    print("‚úì Pipeline workflow completed!")


def main():
    """Main demonstration function."""
    print("üöÄ Excel to CSV Conversion with Structure Preservation")
    print("=" * 60)
    
    try:
        # Basic conversion demo
        csv_files, structure_file, excel_file_path = demonstrate_excel_to_csv_conversion()
        
        # Inspect structure file
        inspect_structure_file(structure_file)
        
        # Demonstrate CSV loading
        demonstrate_csv_loading(csv_files)
        
        # Advanced features
        demonstrate_advanced_features()
        
        # Workflow integration
        demonstrate_workflow_integration(excel_file_path)
        
        print(f"\nüéâ All demonstrations completed successfully!")
        print(f"\nKey Benefits:")
        print(f"  ‚úì Preserves Excel workbook structure in JSON")
        print(f"  ‚úì Maintains sheet relationships and metadata")
        print(f"  ‚úì Enables easy CSV-based data processing")
        print(f"  ‚úì Provides detailed data quality information")
        print(f"  ‚úì Integrates seamlessly with FileUtils workflow")
        
    except Exception as e:
        print(f"‚ùå Error during demonstration: {e}")
        raise


if __name__ == "__main__":
    main()
